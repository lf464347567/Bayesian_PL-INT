{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5904117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, itertools, random\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def compute_v(num_cri:int, num_interval:int, cri_crisp:dict):\n",
    "\n",
    "    value_cri = [torch.as_tensor(list(vals), dtype=torch.float64) for vals in cri_crisp.values()]\n",
    "    assert len(value_cri) == num_cri, f\"num_cri mismatch: got {len(value_cri)} vs {num_cri}\"\n",
    "\n",
    "    num_alter = value_cri[0].numel()\n",
    "    for arr in value_cri[1:]:\n",
    "        assert arr.numel() == num_alter, \"Inconsistent number of alternatives across criteria\"\n",
    "\n",
    "    v_j = []\n",
    "    eps = 1e-12\n",
    "    for i in range(num_cri):\n",
    "        vals = value_cri[i]\n",
    "        v_j.append([])\n",
    "        vmin = torch.min(vals).item()\n",
    "        vmax = torch.max(vals).item()\n",
    "        interval_size = (vmax - vmin) / num_interval if num_interval > 0 else 0.0\n",
    "\n",
    "        x_j = [vmin + k * interval_size for k in range(num_interval + 1)]\n",
    "\n",
    "        for _, g_qi in enumerate(vals.tolist()):\n",
    "            row = []\n",
    "            if interval_size <= eps:\n",
    "\n",
    "                row = [1.0] * num_interval\n",
    "            else:\n",
    "                for t in range(1, num_interval + 1):\n",
    "                    if g_qi > x_j[t]:\n",
    "                        row.append(1.0)\n",
    "                    elif x_j[t - 1] <= g_qi <= x_j[t]:\n",
    "                        denom = x_j[t] - x_j[t - 1]\n",
    "                        row.append(1.0 if denom <= eps else (g_qi - x_j[t - 1]) / denom)\n",
    "                    else:\n",
    "                        row.append(0.0)\n",
    "            v_j[i].append(row)\n",
    "\n",
    "    return torch.tensor(v_j, dtype=torch.float64)  # [num_cri, num_alter, num_interval]\n",
    "\n",
    "\n",
    "def V_INT(v: torch.Tensor):\n",
    "\n",
    "    num_cri, num_alter, num_intervals = v.shape\n",
    "    V_plus, V_minus, V_int = [], [], []\n",
    "\n",
    "    for a in range(num_alter):\n",
    "        V_plus.append([])\n",
    "        V_minus.append([])\n",
    "        c = v[:, a, :].reshape(-1)  \n",
    "        for i in range(num_cri):\n",
    "            via = v[i, a, :]  \n",
    "            for j in range(i + 1, num_cri):\n",
    "                vja = v[j, a, :]\n",
    "                b = (via[:, None] * vja[None, :]).reshape(-1)  \n",
    "                V_plus[a].append(b)\n",
    "                V_minus[a].append(b.clone())  \n",
    "\n",
    "        out = c\n",
    "        for k in range(len(V_plus[a])):\n",
    "            out = torch.cat((out, V_plus[a][k], V_minus[a][k]), dim=0)\n",
    "        V_int.append(out)\n",
    "\n",
    "    return V_int, V_plus, V_minus\n",
    "\n",
    "\n",
    "\n",
    "def interaction(u_int_new: torch.Tensor, num_cri:int, num_interval:int):\n",
    "\n",
    "    device = u_int_new.device\n",
    "    dtype = u_int_new.dtype\n",
    "\n",
    "    numbers = list(range(1, num_cri + 1))\n",
    "    random.shuffle(numbers)\n",
    "    pairs = []\n",
    "    for i in range(0, len(numbers) - 1, 2):\n",
    "        pairs.append(sorted([numbers[i], numbers[i + 1]]))\n",
    "\n",
    "    if len(pairs) > 0:\n",
    "        z = torch.randint(0, 3, (len(pairs),), device=device)\n",
    "\n",
    "    head = num_cri * num_interval\n",
    "    u_int_new[head:] = torch.zeros_like(u_int_new[head:])\n",
    "\n",
    "    nu = list(range(1, num_cri + 1))\n",
    "    pairs_dup = list(itertools.combinations(nu, 2))\n",
    "    block_len = num_interval * num_interval\n",
    "\n",
    "    for idx, pair in enumerate(pairs):\n",
    "        i1 = pair[0] - 1 \n",
    "        j1 = pair[1] - 1\n",
    "        pos = pairs_dup.index((pair[0], pair[1]))\n",
    "\n",
    "        start = head + pos * (block_len * 2)\n",
    "        mid   = start + block_len\n",
    "        end   = start + block_len * 2\n",
    "\n",
    "        upper = []\n",
    "        for k in range(num_interval):\n",
    "            for l in range(num_interval):\n",
    "                uik = u_int_new[i1 * num_interval + k]\n",
    "                ujl = u_int_new[j1 * num_interval + l]\n",
    "                upper.append(torch.minimum(uik, ujl))\n",
    "        upper = torch.stack(upper).to(dtype=dtype, device=device)\n",
    "\n",
    "        rand_block = torch.rand(block_len, dtype=dtype, device=device) * upper\n",
    "\n",
    "        tag = z[idx].item() if len(pairs) > 0 else 0\n",
    "        if tag == 0:\n",
    "            continue\n",
    "        elif tag == 1: \n",
    "            u_int_new[start:mid] = rand_block\n",
    "            u_int_new[mid:end] =  torch.zeros_like(rand_block)\n",
    "        else:           \n",
    "            u_int_new[start:mid] = torch.zeros_like(rand_block)\n",
    "            u_int_new[mid:end]   = -rand_block\n",
    "\n",
    "    s = u_int_new.sum()\n",
    "    u_int_new = u_int_new / (s + torch.as_tensor(1e-12, dtype=dtype, device=device))\n",
    "    return u_int_new\n",
    "\n",
    "\n",
    "def _loglike_logistic(V_list: List[torch.Tensor], u: torch.Tensor,\n",
    "                      Q: List[Tuple[int,int]], omega: float):\n",
    "\n",
    "    dots = torch.stack([torch.dot(Va.to(u.dtype), u) for Va in V_list])  # 先批量算内积\n",
    "    loglike = torch.tensor(0.0, dtype=u.dtype, device=u.device)\n",
    "    for (a, b) in Q:\n",
    "        x = omega * (dots[a] - dots[b])\n",
    "        loglike = loglike + torch.nn.functional.logsigmoid(x)  # log σ(x)\n",
    "    return loglike\n",
    "\n",
    "\n",
    "def calculate_acceptance_probability(u_old: torch.Tensor, u_new: torch.Tensor,\n",
    "                                     Q: List[Tuple[int,int]], alpha: torch.Tensor,\n",
    "                                     V_list: List[torch.Tensor], omega: float,\n",
    "                                     q_alpha: torch.Tensor):\n",
    "\n",
    "    dtype = torch.float64\n",
    "    device = u_old.device\n",
    "    u_old = u_old.to(dtype)\n",
    "    u_new = u_new.to(dtype)\n",
    "    alpha = alpha.to(dtype).to(device)\n",
    "    q_alpha = q_alpha.to(dtype).to(device)\n",
    "\n",
    "    ll_new = _loglike_logistic(V_list, u_new, Q, omega)\n",
    "    ll_old = _loglike_logistic(V_list, u_old, Q, omega)\n",
    "\n",
    "    dir_prior = torch.distributions.Dirichlet(alpha)\n",
    "    dir_prop  = torch.distributions.Dirichlet(q_alpha)\n",
    "\n",
    "    log_ratio = (ll_new - ll_old) \\\n",
    "                + (dir_prior.log_prob(u_new) - dir_prior.log_prob(u_old)) \\\n",
    "                + (dir_prop.log_prob(u_old) - dir_prop.log_prob(u_new))\n",
    "\n",
    "    r = torch.exp(torch.clamp(log_ratio, max=50.0))\n",
    "    r = torch.minimum(r, torch.tensor(1.0, dtype=dtype, device=device))\n",
    "    return r\n",
    "\n",
    "\n",
    "# ===============================\n",
    "def metropolis_hastings(M:int, N:int, num_chains:int, Q:List[Tuple[int,int]], data:dict,\n",
    "                        num_cri:int, num_alter:int, num_interval:int, omega:float,\n",
    "                        alpha_val:float=1.0):\n",
    "\n",
    "    # 维度\n",
    "    num_pairs = num_cri * (num_cri - 1) // 2\n",
    "    num_para = num_cri * num_interval + num_interval * num_interval * num_pairs * 2\n",
    "\n",
    "    alpha   = torch.full((num_para,), float(alpha_val), dtype=torch.float64)\n",
    "    q_alpha = torch.ones_like(alpha)  \n",
    "\n",
    "\n",
    "    v = compute_v(num_cri, num_interval, data)     # [num_cri, num_alter, num_interval]\n",
    "    V_int, _, _ = V_INT(v)                         # list(len=num_alter)\n",
    "    assert len(V_int) == num_alter and V_int[0].numel() == num_para\n",
    "\n",
    "    all_samples = []\n",
    "    all_V_int = V_int  \n",
    "    all_U = []\n",
    "\n",
    "    for _ in range(num_chains):\n",
    "        u = torch.distributions.Dirichlet(alpha).sample()\n",
    "        u = interaction(u, num_cri, num_interval)\n",
    "\n",
    "        samples, U = [], []\n",
    "        for t in range(M + N):\n",
    "            u_new = torch.distributions.Dirichlet(q_alpha).sample()\n",
    "            u_new = interaction(u_new, num_cri, num_interval)\n",
    "\n",
    "            r = calculate_acceptance_probability(u, u_new, Q, alpha, V_int, omega, q_alpha)\n",
    "            if torch.rand(()) < r.item():\n",
    "                u = u_new\n",
    "\n",
    "            if t >= M:  \n",
    "                samples.append(u.clone())\n",
    "                u64 = u.to(torch.float64)\n",
    "                U_INT = [torch.dot(u64, V_int[i].to(u64.dtype)) for i in range(num_alter)]\n",
    "                U.append(U_INT)\n",
    "\n",
    "        all_samples.append(samples)\n",
    "        all_U.append(U)\n",
    "\n",
    "    return all_samples, all_U, all_V_int\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
